{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import requests\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path_pos, path_neg):\n",
    "    pos = pd.read_csv(path_pos, sep=\"\\n\", header=None, names=['review'])\n",
    "    pos['positive']=1\n",
    "    neg = pd.read_csv(path_neg, sep=\"\\n\", header=None, names=['review'])\n",
    "    neg['positive']=0\n",
    "    combined_df = pos.append(neg)\n",
    "    combined_df = shuffle(combined_df, random_state=42)\n",
    "    return(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in training data\n",
    "train = read_data(path_pos=\"Data/IMDb/train/imdb_train_pos.txt\",\n",
    "                  path_neg=\"Data/IMDb/train/imdb_train_neg.txt\")\n",
    "\n",
    "dev = read_data(path_pos=\"Data/IMDb/dev/imdb_dev_pos.txt\",\n",
    "                path_neg=\"Data/IMDb/dev/imdb_dev_neg.txt\")\n",
    "\n",
    "test = read_data(path_pos=\"Data/IMDb/test/imdb_test_pos.txt\",\n",
    "                 path_neg=\"Data/IMDb/test/imdb_test_neg.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of positive reviews\n",
      "-----\n",
      "7483\n",
      "\n",
      "No of negative reviews\n",
      "-----\n",
      "7517\n"
     ]
    }
   ],
   "source": [
    "print(\"No of positive reviews\\n-----\")\n",
    "print(train['positive'].value_counts()[1])\n",
    "print(\"\\nNo of negative reviews\\n-----\")\n",
    "print(train['positive'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate lemmatizer, stopwords, and token retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of unique tokens that have been lemmatized and made lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(string):\n",
    "    sentence_split=nltk.tokenize.sent_tokenize(string)\n",
    "    list_tokens=[]\n",
    "    for sentence in sentence_split:\n",
    "      list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
    "      for token in list_tokens_sentence:\n",
    "        list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "    return list_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create set of stopwords that will be removed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take set of stopwords from nltk\n",
    "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
    "# manually add more punctuation\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\"--\")\n",
    "stopwords.add(\"``\")\n",
    "stopwords.add(\"#\")\n",
    "stopwords.add(\"@\")\n",
    "stopwords.add(\":\")\n",
    "stopwords.add(\"'s\")\n",
    "stopwords.add(\"â€™\")\n",
    "stopwords.add(\"...\")\n",
    "stopwords.add(\"n't\")\n",
    "stopwords.add(\"'re\")\n",
    "stopwords.add(\"'\")\n",
    "stopwords.add(\"-\")\n",
    "stopwords.add(\";\")\n",
    "stopwords.add(\"/\")\n",
    "stopwords.add(\">\")\n",
    "stopwords.add(\"<\")\n",
    "stopwords.add(\"br\")\n",
    "stopwords.add(\"(\")\n",
    "stopwords.add(\")\")\n",
    "stopwords.add(\"''\")\n",
    "stopwords.add(\"&\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class getTokensVocab(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        list_tokens=[]\n",
    "        for index, row in X.iterrows():\n",
    "          sentence_split=nltk.tokenize.sent_tokenize(row['review'])\n",
    "          for sentence in sentence_split:\n",
    "            tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "            for token in tokens:\n",
    "              list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "        return(list_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sortTokens(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        dict_word_freq={}\n",
    "        for token in X:\n",
    "            if token in stopwords: continue\n",
    "            elif token not in dict_word_freq: dict_word_freq[token]=1\n",
    "            elseb: dict_word_freq[token]+=1\n",
    "        sorted_tokens = sorted(dict_word_freq.items(), key=lambda x: x[1], reverse=True)[:self.n]\n",
    "        return(sorted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class getVocabulary(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        vocabulary=[]\n",
    "        for word,frequency in X:\n",
    "            vocabulary.append(word)\n",
    "        return(np.asarray(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainSVMClassifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, train):\n",
    "        self.train = train\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        x_train = get_features(self.train, X)\n",
    "        y_train = np.asarray(self.train['positive'])\n",
    "        svm_clf = sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
    "        svm_clf.fit(x_train,y_train)\n",
    "        return(svm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_SVM = Pipeline([\n",
    "    ('tokenize', getTokensVocab()),\n",
    "    ('sort', sortTokens(100)),\n",
    "    ('get_vocab', getVocabulary()),\n",
    "    ('train_SVM', trainSVMClassifier(train))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = word_count_SVM.fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare results of SVM model between training and dev sets. This can help determine whether the model is under/overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = get_features(train, vocab)\n",
    "train_y = np.asarray(train['positive'])\n",
    "predictions_train = svm_clf.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      7517\n",
      "           1       0.74      0.77      0.75      7483\n",
      "\n",
      "    accuracy                           0.75     15000\n",
      "   macro avg       0.75      0.75      0.75     15000\n",
      "weighted avg       0.75      0.75      0.75     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x = get_features(dev, vocab)\n",
    "dev_y = np.asarray(dev['positive'])\n",
    "predictions = svm_clf.predict(dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74      2482\n",
      "           1       0.73      0.77      0.75      2518\n",
      "\n",
      "    accuracy                           0.74      5000\n",
      "   macro avg       0.74      0.74      0.74      5000\n",
      "weighted avg       0.74      0.74      0.74      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dev_y, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
